\section{Related Work}
\label{sec:related-work}

A computational experiment involves several elements that must be conserved to ensure reproducibility. In last year several studies an initiatives have been conducted for solving its associated challenges~\cite{Hothorn01052011,Sylwester14}. Most of the works addresses the conservation of data and the workflow description, however the computational environment is often neglected. Recent studies have exposed the necessity of publishing adequate descriptions of the runtime environment of experiments to avoid replication hindering~\cite{Rollins201459}. As a result of this trend, more papers are being published\cite{Brown2012} along with their associated experimental materials~\footnote{http://ged.msu.edu/papers/2012-diginorm/}.

A study to evaluate reproducibility in scientific workflows is conducted in~\cite{zhao2012}. The study evaluates a set of domain-specific workflows, available in  myExperiment~\cite{myExperiment}, to identify causes of workflow decay. The study shows that nearly 80\% of the workflows cannot be reproduced, that about 12\% of these reproducibility issues are due to the lack of information about the execution environment, and that 50\% of them are due to the use of third-party resources such as web services and databases that are not available anymore. Note that some of those third-party resource issues could be also considered as execution environment problems. 

Recently, another comprehensive study has been released~\cite{Collberg2015}, surveying 601 papers from ACM conferences and studying how authors share the date and code supporting their results. Authors found that 402 of those papers were supported by code. In this, study authors tried to obtain the code related to each publication, looking for links within the paper itself, searching on code repositories, and contacting the authors when necessary. After code was obtained, several students were asked to try to built it. This whole process was limited by experimental design to a period of 30 minutes. Results show that in 32.3\% of the 402 papers students were able to obtain the code and build the code within the given period. In 48.3\% of the cases, code was built with some extra effort, and in 54\% of the papers code was either built or the authors stated the code would build with reasonable effort. Authors propose, as a result of this study, a {\it sharing specification} for publications that allow to state the level of sharing of each paper.

Replicability and reproducibility of computational experiments using cloud computing resources and software descriptions have been widely proposed as an approach for those studies in which performance is not a key experimental result~\cite{Crick14}.

The Executable Paper Grand Challenge~\cite{elsevierchallenge} and the SIGMOD conference in 2011~\cite{SIGMOD} highlighted the importance of allowing the scientific community to reexamine experiment execution. The conservation of virtual machine (VM) images emerges as a way of preserving the execution environment~\cite{Brammer,SHARE}. However, the high storage demand of VM images remains a challenging problem~\cite{Mao:2014:ROD:2600090.2512348,6552826}. Moreover, the cost of storing and managing data in the Cloud is still high, and the execution of high-interactivity experiments through a network connection to remote virtual machines is also challenging. A list of advantages and challenges of using VMs for achieving reproducibility is exposed in~\cite{Howe2012}. ReproZip~\cite{reprozip} is a provenance-based tool that tracks operating system calls to identify the libraries and data dependencies, as well as the configuration parameters involved in an experiment. The tool combines all these dependencies into a single package that can be used to reproduce an experiment. Although this approach avoids storing VM images, it still requires storing the application binaries and their dependencies. Instead, our work uses semantic annotations to describe these dependencies.

\feedback{@Maria: add more references to previous work on life science reproducibility}
\note{Idafen: there are several references to this in the introduction. Should we repeat them here?}

Galaxy~\cite{goecks2010galaxy}, a well know workflow system in the context of life sciences, proposes a web-service bases system for achieving accessible and reproducible computations. Galaxy hides the implementation details of the underlaying tools for workflow developers, providing a web-based interface for retrieving an analyzing genomic data. Even when this approach has been proved to be successful in several cases, we argue that it does not cover local development of workflows, which is a common case on computational science.  


Software components cannot be preserved just by maintaining their binary executable code, but by guaranteeing the performance of their features. In~\cite{Matthews}, the concept of adequacy is introduced to measure how a software component behaves relatively to a certain set of features. Our work is based on this same concept, where we build a conceptual model to semantically annotate the relevant properties of each software component. Then, we use scripting to reconstruct an equivalent computational environment using these annotations.

A recent and relevant contribution to the state of the art of workflow preservation has been developed within the context of the TIMBUS project~\cite{Mayer2014Ontologies}. The project  aimed to preserve and ensure the availability of business processes and their computational infrastructure, aligned with the enterprise risk and the business continuity managements. They also proposed a semantic approach for describing the execution environment of a process.  However, even though TIMBUS has studied the applicability of their approach to the eScience domain, their approach is mainly focused on business processes.

Semantics have been also proposed in the area of biomedical research as a way for achieving reproducibility of publish experiments~\cite{MaloneSWO2014}. In this work authors propose to annotate the software artifacts in the same way that gene products or phenotypes are annotated. In order to do so, authors propose the {\it Software Ontology} (SWO), a model for describing the software involved on the storage and management of data. The SWO have many concepts in common with the WICUS ontology  network, but is specialized on the biomedical domain, focusing on model biomedical-related software specifically. WICUS aims to be a more generic ontology that can be applied in different scientific domains.

